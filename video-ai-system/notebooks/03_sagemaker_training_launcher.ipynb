{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Production-Grade SageMaker Training Launcher for VideoMAE\n",
        "\n",
        "This notebook provides a sophisticated and robust interface for launching and managing VideoMAE pre-training jobs on Amazon SageMaker. It is designed for production-level workflows, incorporating best practices for configuration, cost management, error handling, and MLOps.\n",
        "\n",
        "**Key Features:**\n",
        "\n",
        "1.  **Centralized Configuration:** All parameters are defined in a single block for easy management.\n",
        "2.  **Cost-Effective Spot Training:** Integrated support for SageMaker Managed Spot Instances.\n",
        "3.  **Live Log Streaming:** Training job logs are streamed directly into the notebook for real-time monitoring.\n",
        "4.  **Model Registry Integration:** A full workflow to register the trained model into the SageMaker Model Registry for versioning and deployment.\n",
        "5.  **Robust Error Handling & Recovery:** Jobs are launched within `try...except` blocks, and examples are provided for attaching to existing jobs.\n",
        "6.  **Framework Synchronization:** PyTorch and Python versions are aligned with the project's dependencies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Session Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sagemaker\n",
        "import boto3\n",
        "import os\n",
        "import time\n",
        "from sagemaker.pytorch import PyTorch\n",
        "from sagemaker.tuner import HyperparameterTuner, IntegerParameter, ContinuousParameter\n",
        "from sagemaker.inputs import TrainingInput\n",
        "from sagemaker.model_metrics import ModelMetrics, MetricsSource\n",
        "from sagemaker.workflow.parameters import ParameterString\n",
        "\n",
        "print(f\"SageMaker SDK Version: {sagemaker.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sagemaker_session = sagemaker.Session()\n",
        "boto_session = boto3.Session()\n",
        "\n",
        "region = sagemaker_session.boto_region_name\n",
        "bucket = sagemaker_session.default_bucket()\n",
        "account_id = sagemaker_session.boto_principal_arn.split(':')[4]\n",
        "\n",
        "role = sagemaker.get_execution_role()\n",
        "\n",
        "print(f\"Region: {region}\")\n",
        "print(f\"Account ID: {account_id}\")\n",
        "print(f\"IAM Role: {role}\")\n",
        "print(f\"S3 Bucket: {bucket}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Training Job Configuration\n",
        "\n",
        "All job-related parameters are defined here. This centralized approach simplifies customization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "project_name = 'videomae-pretraining-production'\n",
        "\n",
        "# --- S3 Paths ---\n",
        "# Your dataset should be uploaded here before running the notebook.\n",
        "s3_data_path = f's3://{bucket}/{project_name}/data'\n",
        "s3_output_path = f's3://{bucket}/{project_name}/output'\n",
        "\n",
        "# --- Training Script ---\n",
        "source_dir = '../scripts/'\n",
        "entry_point = 'train.py'\n",
        "\n",
        "# --- Framework and Instance ---\n",
        "# mmcv==2.1.0 is compatible with torch==2.0 and cuda 11.8\n",
        "framework_version = '2.0'\n",
        "py_version = 'py310'\n",
        "instance_type = 'ml.p3.2xlarge'\n",
        "input_mode = 'File' # Use 'File', 'Pipe', or 'FastFile' depending on dataset size\n",
        "\n",
        "# --- Cost-Saving: Spot Instance Configuration ---\n",
        "use_spot_instances = True\n",
        "max_run_seconds = 3600 * 4  # Max training time (4 hours)\n",
        "max_wait_seconds = 3600 * 6  # Max time to wait for a spot instance (6 hours)\n",
        "\n",
        "# --- Model Registry Configuration ---\n",
        "model_package_group_name = project_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### IAM Role Permissions\n",
        "\n",
        "Ensure the SageMaker Execution Role (`{role}`) has the following permissions:\n",
        "- `AmazonS3FullAccess` (or scoped-down access to the specific `s3_data_path` and `s3_output_path`).\n",
        "- `AmazonSageMakerFullAccess`.\n",
        "- `iam:PassRole` on the role itself.\n",
        "- If using the Model Registry, permissions like `sagemaker:CreateModelPackageGroup`, `sagemaker:CreateModelPackage`, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Launch a Single, Monitored Training Job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hyperparameters = {\n",
        "    'epochs': 15,\n",
        "    'lr': 1.5e-4,\n",
        "    'batch-size': 8,\n",
        "    'warmup-epochs': 2\n",
        "}\n",
        "\n",
        "base_job_name = f\"{project_name}-single\"\n",
        "training_job_name = f\"{base_job_name}-{int(time.time())}\"\n",
        "\n",
        "metric_definitions = [\n",
        "    {'Name': 'train:loss', 'Regex': 'Training-Loss: ([0-9\\.]+)'}\n",
        "]\n",
        "\n",
        "estimator = PyTorch(\n",
        "    entry_point=entry_point,\n",
        "    source_dir=source_dir,\n",
        "    role=role,\n",
        "    instance_count=1,\n",
        "    instance_type=instance_type,\n",
        "    framework_version=framework_version,\n",
        "    py_version=py_version,\n",
        "    hyperparameters=hyperparameters,\n",
        "    output_path=s3_output_path,\n",
        "    metric_definitions=metric_definitions,\n",
        "    input_mode=input_mode,\n",
        "    use_spot_instances=use_spot_instances,\n",
        "    max_run=max_run_seconds,\n",
        "    max_wait=max_wait_seconds if use_spot_instances else None\n",
        ")\n",
        "\n",
        "training_input = TrainingInput(s3_data=s3_data_path, content_type='application/x-video')\n",
        "\n",
        "print(f\"Launching single training job: {training_job_name}\")\n",
        "\n",
        "try:\n",
        "    estimator.fit({'training': training_input}, job_name=training_job_name, wait=False)\n",
        "    print(f\"Job launched successfully. You can view it in the SageMaker console.\")\n",
        "    print(f\"Streaming logs for job '{training_job_name}':\")\n",
        "    sagemaker_session.logs_for_job(job_name=training_job_name, wait=True)\n",
        "except Exception as e:\n",
        "    print(f\"\\nError launching or monitoring training job: {e}\")\n",
        "    print(f\"Check CloudWatch logs for job '{training_job_name}' for more details.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Launch a Hyperparameter Tuning Job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hyperparameter_ranges = {\n",
        "    'lr': ContinuousParameter(1e-5, 1e-3)\n",
        "}\n",
        "\n",
        "tuner = HyperparameterTuner(\n",
        "    estimator=estimator, # Re-uses the same estimator configuration\n",
        "    objective_metric_name='train:loss',\n",
        "    hyperparameter_ranges=hyperparameter_ranges,\n",
        "    objective_type='Minimize',\n",
        "    max_jobs=10,\n",
        "    max_parallel_jobs=2,\n",
        "    base_tuning_job_name=f\"{project_name}-hpo\"\n",
        ")\n",
        "\n",
        "tuning_job_name = f\"{project_name}-hpo-{int(time.time())}\"\n",
        "print(f\"Launching hyperparameter tuning job: {tuning_job_name}\")\n",
        "\n",
        "try:\n",
        "    tuner.fit({'training': training_input}, job_name=tuning_job_name, wait=True)\n",
        "except Exception as e:\n",
        "    print(f\"\\nError launching tuning job: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Analyze Tuning Results and Register the Best Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    tuner_analyzer = sagemaker.analytics.HyperparameterTuningJobAnalytics(tuning_job_name)\n",
        "    best_job_name = tuner_analyzer.best_training_job()['TrainingJobName']\n",
        "    print(f\"Best training job found: {best_job_name}\")\n",
        "\n",
        "    # Attach to the best estimator\n",
        "    best_estimator = PyTorch.attach(best_job_name)\n",
        "    model_artifacts = best_estimator.model_data\n",
        "    print(f\"Model artifacts for the best job are at: {model_artifacts}\")\n",
        "\n",
        "    # Create a SageMaker Model Package Group for versioning\n",
        "    sm_client = sagemaker_session.sagemaker_client\n",
        "    try:\n",
        "        sm_client.create_model_package_group(\n",
        "            ModelPackageGroupName=model_package_group_name,\n",
        "            ModelPackageGroupDescription=f\"Models for {project_name}\"\n",
        "        )\n",
        "        print(f\"Created Model Package Group: {model_package_group_name}\")\n",
        "    except sm_client.exceptions.ClientError as e:\n",
        "        if e.response['Error']['Code'] == 'ValidationException':\n",
        "            print(f\"Model Package Group '{model_package_group_name}' already exists.\")\n",
        "        else:\n",
        "            raise\n",
        "\n",
        "    # Register the model\n",
        "    model_package = best_estimator.register(\n",
        "        content_types=[\"application/x-video\"],\n",
        "        response_types=[\"application/json\"],\n",
        "        inference_instances=[\"ml.g4dn.xlarge\"], # Example instance for deployment\n",
        "        transform_instances=[\"ml.m5.large\"],\n",
        "        model_package_group_name=model_package_group_name,\n",
        "        approval_status=\"PendingManualApproval\"\n",
        "    )\n",
        "    print(f\"\\nSuccessfully registered model version: {model_package.model_package_arn}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Could not analyze or register model. It may have failed. Error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Cleanup (Optional)\n",
        "\n",
        "To avoid incurring costs, you can delete the resources created. If you deployed an endpoint, delete it first. Here, we show how to delete the model versions and the model group."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# sm_client = sagemaker_session.sagemaker_client\n",
        "# try:\n",
        "#     # List all versions in the model group\n",
        "#     model_packages = sm_client.list_model_packages(ModelPackageGroupName=model_package_group_name)['ModelPackageSummaryList']\n",
        "#     for mp in model_packages:\n",
        "#         print(f\"Deleting model package: {mp['ModelPackageArn']}\")\n",
        "#         sm_client.delete_model_package(ModelPackageName=mp['ModelPackageArn'])\n",
        "    \n",
        "#     # Delete the model group itself\n",
        "#     print(f\"Deleting model package group: {model_package_group_name}\")\n",
        "#     sm_client.delete_model_package_group(ModelPackageGroupName=model_package_group_name)\n",
        "#     print(\"Cleanup complete.\")\n",
        "# except sm_client.exceptions.ClientError as e:\n",
        "#     print(f\"Could not perform cleanup. Error: {e}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (Data Science)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
