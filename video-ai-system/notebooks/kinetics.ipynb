{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a8a280b0367b44f09c58c595f14bea84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_da11d0e598f4454583a1ee989ee01e94",
              "IPY_MODEL_d1a9b10a5d434e15a25962b77b2a564d",
              "IPY_MODEL_4729689763c74098a952a2e89cc831ee"
            ],
            "layout": "IPY_MODEL_b0e2aff135a943549d9715ae3a82e90b"
          }
        },
        "da11d0e598f4454583a1ee989ee01e94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad2c57195d0549c6bc490e8d2016fd51",
            "placeholder": "​",
            "style": "IPY_MODEL_40a4b01997304b83ab2ba48cd76f3d5a",
            "value": "Processing Clips:   0%"
          }
        },
        "d1a9b10a5d434e15a25962b77b2a564d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a1263ef44c34f2e8360a3a3e57af99b",
            "max": 771,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e59d3e16a5a34fc1a2d373a8da6b78a6",
            "value": 3
          }
        },
        "4729689763c74098a952a2e89cc831ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9d04980d602467aab8e3d7416aa60d9",
            "placeholder": "​",
            "style": "IPY_MODEL_232fe896eba344fbb3b6c9633b62f4e0",
            "value": " 3/771 [00:52&lt;3:21:13, 15.72s/clip, failed=2, succeeded=1]"
          }
        },
        "b0e2aff135a943549d9715ae3a82e90b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad2c57195d0549c6bc490e8d2016fd51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40a4b01997304b83ab2ba48cd76f3d5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a1263ef44c34f2e8360a3a3e57af99b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e59d3e16a5a34fc1a2d373a8da6b78a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f9d04980d602467aab8e3d7416aa60d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "232fe896eba344fbb3b6c9633b62f4e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frmMWltPupmH"
      },
      "source": [
        "VIDEO EXTRACT AI"
      ],
      "id": "frmMWltPupmH"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "on1WSw2tupmI",
        "outputId": "017269f6-08b6-4dcf-a723-569b34c4b34f"
      },
      "source": [
        "# CELL 1: SETUP, DEPENDENCIES, AND GOOGLE DRIVE CONFIGURATION\n",
        "import os\n",
        "import sys\n",
        "import yaml\n",
        "from pathlib import Path\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List\n",
        "\n",
        "# --- 1. Mount Google Drive ---\n",
        "# This is the first and most important step for the new workflow.\n",
        "# You will be prompted to authorize Colab to access your Drive.\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"✅ Google Drive mounted successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Failed to mount Google Drive: {e}\", file=sys.stderr)\n",
        "    sys.exit(1)\n",
        "\n",
        "# --- 2. Install Dependencies ---\n",
        "print(\"\\n--- Installing Python packages ---\")\n",
        "!pip install -q pydantic yt-dlp ffmpeg-python pandas tqdm pyyaml\n",
        "\n",
        "print(\"\\n--- Installing system FFmpeg (with NVENC) ---\")\n",
        "!apt-get update -qq && apt-get install -y -qq ffmpeg\n",
        "\n",
        "print(\"\\n--- Verifying GPU and NVENC ---\")\n",
        "!nvidia-smi --query-gpu=name,driver_version,memory.total --format=csv,noheader\n",
        "!ffmpeg -hide_banner -hwaccels | grep -q 'cuda' && echo \"✅ CUDA HWAccel found.\" || echo \"⚠️ CUDA HWAccel not found.\"\n",
        "!ffmpeg -hide_banner -encoders | grep -q 'nvenc' && echo \"✅ NVENC encoders found.\" || echo \"⚠️ NVENC encoders not found.\"\n",
        "\n",
        "# --- 3. Define NEW Configuration Schema for Google Drive ---\n",
        "# This schema is tailored for the Kinetics-to-Drive workflow.\n",
        "class DriveConfig(BaseModel):\n",
        "    # Example: \"My Drive/Kinetics-700-Clips\"\n",
        "    # This path will be created in your Google Drive root.\n",
        "    output_directory: str\n",
        "\n",
        "class EncodingParams(BaseModel):\n",
        "    cq: int = 23\n",
        "    preset: str = 'p6'\n",
        "\n",
        "class VideoProcessingConfig(BaseModel):\n",
        "    vcodec: str = \"h264_nvenc\"\n",
        "    target_fps: int = 30\n",
        "    encoding_params: EncodingParams = Field(default_factory=EncodingParams)\n",
        "    run_output_dir: Path = Field(default_factory=lambda: Path.cwd() / \"temp_clips\")\n",
        "\n",
        "class ExecutionConfig(BaseModel):\n",
        "    max_workers: int = 6 # Tuned for Colab's I/O and GPU balance\n",
        "    sleep_interval_seconds: int = 2\n",
        "\n",
        "class MainConfig(BaseModel):\n",
        "    drive: DriveConfig\n",
        "    video_processing: VideoProcessingConfig\n",
        "    execution: ExecutionConfig\n",
        "\n",
        "# --- 4. Load and Validate Configuration ---\n",
        "# We will create a default config here in the code to simplify things.\n",
        "# You can also save this as /content/config.yaml if you prefer.\n",
        "CONFIG_YAML = \"\"\"\n",
        "drive:\n",
        "  output_directory: \"My Drive/Kinetics-700-Clips\"\n",
        "\n",
        "video_processing:\n",
        "  vcodec: \"h264_nvenc\"\n",
        "  target_fps: 30\n",
        "  encoding_params:\n",
        "    cq: 23\n",
        "    preset: \"p6\"\n",
        "\n",
        "execution:\n",
        "  max_workers: 6\n",
        "  sleep_interval_seconds: 2\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\n--- Loading Configuration ---\")\n",
        "try:\n",
        "    yaml_data = yaml.safe_load(CONFIG_YAML)\n",
        "    cfg = MainConfig.model_validate(yaml_data)\n",
        "\n",
        "    # Create the temporary local directory for clips before they are moved to Drive\n",
        "    cfg.video_processing.run_output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Create the final output directory in Google Drive\n",
        "    drive_output_path = Path(\"/content/drive\") / cfg.drive.output_directory\n",
        "    drive_output_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    print(\"✅ Configuration loaded and validated successfully.\")\n",
        "    print(f\"   - Video Codec: {cfg.video_processing.vcodec}\")\n",
        "    print(f\"   - Temp Clip Dir: {cfg.video_processing.run_output_dir}\")\n",
        "    print(f\"   - Final Drive Dir: {drive_output_path}\")\n",
        "    print(f\"   - Max Workers: {cfg.execution.max_workers}\")\n",
        "\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error loading config: {e}\", file=sys.stderr)\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    sys.exit(1)\n",
        "\n",
        "print(\"\\n✅ Cell 1 complete. Environment is ready for Kinetics-700 processing.\")"
      ],
      "id": "on1WSw2tupmI",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "✅ Google Drive mounted successfully.\n",
            "\n",
            "--- Installing Python packages ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:QFxYxUc2bTA_0: Processing failed. Reason: yt-dlp failed: ERROR: [youtube] QFxYxUc2bTA: Requested format is not available. Use --list-formats for a list of available formats\n",
            "ERROR:root:ajX_uYAchD0_34: Processing failed. Reason: yt-dlp failed: ERROR: [youtube] ajX_uYAchD0: Requested format is not available. Use --list-formats for a list of available formats\n",
            "ERROR:root:yFBiAIlr2d8_30: Processing failed. Reason: yt-dlp failed: ERROR: ffmpeg exited with code 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Installing system FFmpeg (with NVENC) ---\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "\n",
            "--- Verifying GPU and NVENC ---\n",
            "Tesla T4, 550.54.15, 15360 MiB\n",
            "✅ CUDA HWAccel found.\n",
            "✅ NVENC encoders found.\n",
            "\n",
            "--- Loading Configuration ---\n",
            "✅ Configuration loaded and validated successfully.\n",
            "   - Video Codec: h264_nvenc\n",
            "   - Temp Clip Dir: /content/temp_clips\n",
            "   - Final Drive Dir: /content/drive/My Drive/Kinetics-700-Clips\n",
            "   - Max Workers: 6\n",
            "\n",
            "✅ Cell 1 complete. Environment is ready for Kinetics-700 processing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 2: KINETICS-700 DATASET LOADING AND SAMPLING\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "import logging\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\")\n",
        "\n",
        "# --- 1. Download the Official Kinetics-700 Annotations ---\n",
        "# We will use the validation set as it's smaller and good for a 1000-clip sample.\n",
        "KINETICS_URL = \"https://storage.googleapis.com/deepmind-media/Datasets/kinetics700_2020.tar.gz\"\n",
        "TAR_FILE = Path(\"kinetics700_2020.tar.gz\")\n",
        "ANNOTATION_CSV = Path(\"kinetics700_2020/validate.csv\")\n",
        "\n",
        "print(f\"--- Loading Kinetics-700 Dataset ---\")\n",
        "if not ANNOTATION_CSV.exists():\n",
        "    logging.info(f\"Downloading and extracting Kinetics-700 annotations from {KINETICS_URL}...\")\n",
        "    !wget -q -O {TAR_FILE} {KINETICS_URL}\n",
        "    !tar -xf {TAR_FILE}\n",
        "    logging.info(\"Annotations extracted successfully.\")\n",
        "else:\n",
        "    logging.info(\"Kinetics-700 annotations already exist.\")\n",
        "\n",
        "# --- 2. Load, Sample, and Prepare the Data ---\n",
        "try:\n",
        "    df = pd.read_csv(ANNOTATION_CSV)\n",
        "    logging.info(f\"Loaded {len(df)} total clips from the validation set.\")\n",
        "\n",
        "    # Take a random sample of 1000 clips\n",
        "    # Using a fixed random_state ensures the sample is the same every time you run the notebook.\n",
        "    # NOTE: You can increase n=1000 to a larger number to get more final clips.\n",
        "    master_df = df.sample(n=1000, random_state=42).copy()\n",
        "    logging.info(f\"Sampled 1000 random clips for processing.\")\n",
        "\n",
        "    # The Kinetics dataset uses 'label' for the class name, which is perfect.\n",
        "    # We will create a unique ID for our database based on the youtube_id and start time.\n",
        "    master_df['video_id'] = master_df['youtube_id'] + '_' + master_df['time_start'].astype(str)\n",
        "\n",
        "except Exception as e:\n",
        "    logging.error(f\"Failed to load or sample the Kinetics CSV: {e}\", exc_info=True)\n",
        "    sys.exit(1)\n",
        "\n",
        "# --- 3. Validate and Initialize Database ---\n",
        "master_df.dropna(subset=['youtube_id', 'label', 'time_start', 'time_end'], inplace=True)\n",
        "logging.info(f\"After dropping nulls: {len(master_df)} clips remain.\")\n",
        "master_df.drop_duplicates('video_id', inplace=True)\n",
        "logging.info(f\"After removing duplicates: {len(master_df)} unique clips remain.\")\n",
        "\n",
        "# --- 4. Seed the Database with New Videos ---\n",
        "DB_PATH = Path(\"/content/video_state.db\")\n",
        "with sqlite3.connect(str(DB_PATH)) as con:\n",
        "    con.execute(\"CREATE TABLE IF NOT EXISTS videos (video_id TEXT PRIMARY KEY, label TEXT, status TEXT NOT NULL, drive_path TEXT, reason TEXT, updated_at TIMESTAMP)\")\n",
        "    cursor = con.cursor()\n",
        "    cursor.execute(\"SELECT video_id FROM videos\")\n",
        "    existing_vids = {row[0] for row in cursor.fetchall()}\n",
        "    to_add_df = master_df[~master_df['video_id'].isin(existing_vids)]\n",
        "    if not to_add_df.empty:\n",
        "        recs = to_add_df.assign(status='PENDING')[['video_id','label','status']]\n",
        "        recs.to_sql('videos', con, if_exists='append', index=False)\n",
        "        logging.info(f\"DB seeded with {len(recs)} new clips.\")\n",
        "    else:\n",
        "        logging.info(\"No new clips to add to the database.\")\n",
        "\n",
        "# --- 5. Prepare Final Queue for Processing ---\n",
        "print(\"\\n--- Preparing processing queue ---\")\n",
        "with sqlite3.connect(str(DB_PATH)) as con:\n",
        "    pending_df = pd.read_sql(\"SELECT video_id FROM videos WHERE status='PENDING'\", con)\n",
        "if pending_df.empty:\n",
        "    logging.info(\"✅ No clips with status 'PENDING' found. Nothing to process.\")\n",
        "    hq_df = pd.DataFrame()\n",
        "else:\n",
        "    # Merge to get all necessary columns (youtube_id, label, start, end) for the clips we need to process\n",
        "    hq_df = master_df.merge(pending_df, on='video_id')\n",
        "    logging.info(f\"Found {len(hq_df)} clips in the queue to process.\")\n",
        "\n",
        "print(f\"\\n✅ Cell 2 complete. Videos queued for processing: {len(hq_df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ra-Cb71JzIPM",
        "outputId": "a29727c5-5ccd-4d7b-80ae-090e87d9c751"
      },
      "id": "ra-Cb71JzIPM",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Loading Kinetics-700 Dataset ---\n",
            "\n",
            "--- Preparing processing queue ---\n",
            "\n",
            "✅ Cell 2 complete. Videos queued for processing: 771\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 3: THE KINETICS CLIP PROCESSING ENGINE (TRIM, ENCODE, AND SAVE TO DRIVE)\n",
        "import subprocess\n",
        "import traceback\n",
        "import sqlite3\n",
        "from pathlib import Path\n",
        "import logging\n",
        "import shutil\n",
        "\n",
        "DB_PATH = Path(\"/content/video_state.db\")\n",
        "\n",
        "def update_status(vid, status, drive_path=None, reason=None):\n",
        "    \"\"\"Updates the clip status in the central SQLite database.\"\"\"\n",
        "    with sqlite3.connect(str(DB_PATH), timeout=10) as con:\n",
        "        con.execute(\"UPDATE videos SET status=?, drive_path=?, reason=?, updated_at=CURRENT_TIMESTAMP WHERE video_id=?\",\n",
        "                  (status, drive_path or '', str(reason) or '', vid))\n",
        "\n",
        "def process_video_gpu(row, config):\n",
        "    \"\"\"\n",
        "    Downloads a full YouTube video, uses FFmpeg to trim the specified clip,\n",
        "    encodes it with the GPU, and moves the final clip to Google Drive.\n",
        "    \"\"\"\n",
        "    # --- 1. Setup paths and variables ---\n",
        "    # A unique ID for this specific clip\n",
        "    clip_id = row.video_id\n",
        "    # The original YouTube ID\n",
        "    youtube_id = row.youtube_id\n",
        "    # Sanitize the label to create a clean directory name\n",
        "    label = \"\".join(c if c.isalnum() else '_' for c in row.label)\n",
        "\n",
        "    # Define the final path in Google Drive\n",
        "    drive_output_dir = Path(\"/content/drive\") / config.drive.output_directory / label\n",
        "    drive_output_dir.mkdir(parents=True, exist_ok=True) # Ensure the label directory exists\n",
        "    final_drive_path = drive_output_dir / f\"clip_{clip_id}.mp4\"\n",
        "\n",
        "    # Define a temporary path on the local Colab disk for processing\n",
        "    temp_output_path = config.video_processing.run_output_dir / f\"{clip_id}.mp4\"\n",
        "\n",
        "    youtube_url = f\"https://www.youtube.com/watch?v={youtube_id}\"\n",
        "\n",
        "    p_yt, p_ff = None, None\n",
        "    try:\n",
        "        # --- 2. Define yt-dlp and FFmpeg commands ---\n",
        "        # UPDATED: Format string now looks for 480p or higher.\n",
        "        yt_dlp_cmd = [\n",
        "            'yt-dlp', '--quiet', '--no-warnings',\n",
        "            # Get the best 480p-or-higher stream available.\n",
        "            '-f', 'bestvideo[height>=480]+bestaudio/best[height>=480]',\n",
        "            '-o', '-', youtube_url\n",
        "        ]\n",
        "\n",
        "        vp_cfg = config.video_processing\n",
        "        start_time = row.time_start\n",
        "        end_time = row.time_end\n",
        "\n",
        "        # CRITICAL: The FFmpeg command now includes trimming flags.\n",
        "        # -ss [start] -to [end] are placed AFTER the input for frame accuracy.\n",
        "        ffmpeg_cmd = [\n",
        "            'ffmpeg', '-y', '-hide_banner',\n",
        "            '-i', 'pipe:0', # Input from yt-dlp pipe\n",
        "            '-ss', str(start_time),\n",
        "            '-to', str(end_time),\n",
        "            '-max_muxing_queue_size', '1024',\n",
        "            '-c:v', vp_cfg.vcodec,\n",
        "            '-preset', vp_cfg.encoding_params.preset,\n",
        "            '-cq', str(vp_cfg.encoding_params.cq),\n",
        "            '-r', str(vp_cfg.target_fps),\n",
        "            '-pix_fmt', 'yuv420p',\n",
        "            '-c:a', 'aac',\n",
        "            str(temp_output_path) # Output to the temporary local path\n",
        "        ]\n",
        "\n",
        "        logging.info(f\"{clip_id}: Starting trim/encode: {start_time}s to {end_time}s\")\n",
        "\n",
        "        # --- 3. Execute the process pipe ---\n",
        "        p_yt = subprocess.Popen(yt_dlp_cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "        p_ff = subprocess.Popen(ffmpeg_cmd, stdin=p_yt.stdout, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "        if p_yt.stdout: p_yt.stdout.close()\n",
        "\n",
        "        ff_stdout, ff_stderr = p_ff.communicate(timeout=600) # 10-minute timeout\n",
        "        yt_stdout, yt_stderr = p_yt.communicate()\n",
        "\n",
        "        if p_yt.returncode != 0: raise RuntimeError(f\"yt-dlp failed: {yt_stderr.decode().strip()}\")\n",
        "        if p_ff.returncode != 0: raise RuntimeError(f\"FFmpeg failed: {ff_stderr.decode().strip()}\")\n",
        "        if not temp_output_path.exists() or temp_output_path.stat().st_size < 1024:\n",
        "            raise RuntimeError(f\"FFmpeg ran, but the output clip is missing or too small.\")\n",
        "\n",
        "        # --- 4. Move final clip to Google Drive ---\n",
        "        logging.info(f\"{clip_id}: Moving clip to Google Drive: {final_drive_path}\")\n",
        "        shutil.move(str(temp_output_path), str(final_drive_path))\n",
        "\n",
        "        update_status(clip_id, 'SUCCESS', drive_path=str(final_drive_path))\n",
        "        return True, None\n",
        "\n",
        "    except Exception as e:\n",
        "        error_reason = str(e).splitlines()[0]\n",
        "        logging.error(f\"{clip_id}: Processing failed. Reason: {error_reason}\")\n",
        "        update_status(clip_id, 'FAILURE', reason=error_reason)\n",
        "        return False, error_reason\n",
        "    finally:\n",
        "        # Cleanup processes and temporary files\n",
        "        if p_yt and p_yt.poll() is None: p_yt.kill()\n",
        "        if p_ff and p_ff.poll() is None: p_ff.kill()\n",
        "        if temp_output_path.exists():\n",
        "            temp_output_path.unlink()\n",
        "\n",
        "print(\"✅ Cell 3 complete. Clip processing engine is ready.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Agok87p5vywu",
        "outputId": "8182c15d-76aa-4236-f96c-bb2c89c8fe03"
      },
      "id": "Agok87p5vywu",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Cell 3 complete. Clip processing engine is ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "a8a280b0367b44f09c58c595f14bea84",
            "da11d0e598f4454583a1ee989ee01e94",
            "d1a9b10a5d434e15a25962b77b2a564d",
            "4729689763c74098a952a2e89cc831ee",
            "b0e2aff135a943549d9715ae3a82e90b",
            "ad2c57195d0549c6bc490e8d2016fd51",
            "40a4b01997304b83ab2ba48cd76f3d5a",
            "6a1263ef44c34f2e8360a3a3e57af99b",
            "e59d3e16a5a34fc1a2d373a8da6b78a6",
            "f9d04980d602467aab8e3d7416aa60d9",
            "232fe896eba344fbb3b6c9633b62f4e0"
          ]
        },
        "id": "FAiosm5_upmK",
        "outputId": "c23c3661-6942-43e5-af47-92980fa4c5d6"
      },
      "source": [
        "# CELL 4: PARALLEL EXECUTION, MONITORING, AND VERIFICATION (DRIVE-READY)\n",
        "import time\n",
        "import random\n",
        "import sys\n",
        "import logging\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from tqdm.auto import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "if 'hq_df' not in globals() or hq_df.empty:\n",
        "    logging.warning(\"✅ No clips found in the queue. Nothing to do. Pipeline finished.\")\n",
        "else:\n",
        "    success_count = 0\n",
        "    failure_count = 0\n",
        "    start_time = time.time()\n",
        "    max_workers = cfg.execution.max_workers\n",
        "\n",
        "    def run_process_wrapper(row):\n",
        "        time.sleep(random.uniform(1, cfg.execution.sleep_interval_seconds))\n",
        "        return process_video_gpu(row, cfg)\n",
        "\n",
        "    print(f\"--- Starting parallel processing of {len(hq_df)} clips using {max_workers} workers ---\")\n",
        "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "        future_to_clip = {executor.submit(run_process_wrapper, row): row.video_id for _, row in hq_df.iterrows()}\n",
        "        with tqdm(total=len(hq_df), desc=\"Processing Clips\", unit=\"clip\") as pbar:\n",
        "            for future in as_completed(future_to_clip):\n",
        "                clip_id = future_to_clip[future]\n",
        "                try:\n",
        "                    ok, reason = future.result()\n",
        "                    if ok: success_count += 1\n",
        "                    else: failure_count += 1\n",
        "                except Exception as e:\n",
        "                    failure_count += 1\n",
        "                    logging.critical(f\"{clip_id}: An unexpected exception occurred: {e}\", exc_info=True)\n",
        "                    update_status(clip_id, 'FAILURE', reason=f\"Executor-level exception: {e}\")\n",
        "                pbar.update(1)\n",
        "                pbar.set_postfix(succeeded=success_count, failed=failure_count, refresh=True)\n",
        "\n",
        "    end_time = time.time()\n",
        "    total_processed = success_count + failure_count\n",
        "    duration_minutes = (end_time - start_time) / 60 if (end_time - start_time) > 0 else 0\n",
        "    rate = total_processed / duration_minutes if duration_minutes > 0 else 0\n",
        "    print(\"\\n--- PROCESSING COMPLETE ---\")\n",
        "    print(f\"✅ Succeeded: {success_count}\")\n",
        "    print(f\"❌ Failed:    {failure_count}\")\n",
        "    print(f\"⏱️ Total processed: {total_processed} in {duration_minutes:.2f} minutes ({rate:.2f} clips/min)\")\n",
        "\n",
        "    # --- Verification step updated for Google Drive ---\n",
        "    print(\"\\n--- Verifying sample of successful clips in Google Drive ---\")\n",
        "    try:\n",
        "        with sqlite3.connect(str(DB_PATH)) as con:\n",
        "            verified_df = pd.read_sql(\"SELECT drive_path FROM videos WHERE status='SUCCESS' AND drive_path != '' LIMIT 5\", con)\n",
        "        if verified_df.empty:\n",
        "            print(\"⚠️ No successful clips found in the database to verify.\")\n",
        "        else:\n",
        "            print(f\"Checking for {len(verified_df)} file(s) in Google Drive...\")\n",
        "            verified_count = 0\n",
        "            for drive_path_str in verified_df['drive_path']:\n",
        "                if Path(drive_path_str).exists():\n",
        "                    print(f\"  ✅ Found: {drive_path_str}\")\n",
        "                    verified_count += 1\n",
        "                else:\n",
        "                    print(f\"  ❌ FAILED TO FIND: {drive_path_str}\")\n",
        "            print(f\"\\nSuccessfully verified {verified_count}/{len(verified_df)} sample files.\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Could not perform Google Drive verification: {e}\")\n",
        "\n",
        "    print(\"\\n✅ Pipeline Finished.\")"
      ],
      "id": "FAiosm5_upmK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting parallel processing of 771 clips using 6 workers ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processing Clips:   0%|          | 0/771 [00:00<?, ?clip/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a8a280b0367b44f09c58c595f14bea84"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:9BG75zyN-C4_29: Processing failed. Reason: yt-dlp failed: ERROR: ffmpeg exited with code 1\n",
            "ERROR:root:QlYqu2EmouU_15: Processing failed. Reason: yt-dlp failed: ERROR: [youtube] QlYqu2EmouU: Requested format is not available. Use --list-formats for a list of available formats\n",
            "ERROR:root:WW6wDRNon9A_21: Processing failed. Reason: yt-dlp failed: ERROR: [youtube] WW6wDRNon9A: Requested format is not available. Use --list-formats for a list of available formats\n",
            "ERROR:root:ZwlQcUa8kdI_96: Processing failed. Reason: yt-dlp failed: ERROR: ffmpeg exited with code 1\n",
            "ERROR:root:QlYqu2EmouU_15: Processing failed. Reason: yt-dlp failed: ERROR: [youtube] QlYqu2EmouU: Requested format is not available. Use --list-formats for a list of available formats\n"
          ]
        }
      ]
    }
  ]
}